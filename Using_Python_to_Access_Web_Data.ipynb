{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPmYb4MAtj5BQlJ/fiuvVsj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iaran97/PY4E/blob/main/Using_Python_to_Access_Web_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# week-1"
      ],
      "metadata": {
        "id": "GOyCcuUA1aZt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n"
      ],
      "metadata": {
        "id": "l-_XoPKDEUm2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fwfhuNPf04lR"
      },
      "outputs": [],
      "source": [
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "data = urllib.request.urlopen(\"http://py4e-data.dr-chuck.net/regex_sum_42.txt\") # it's a file like object and works just like a file\n"
      ],
      "metadata": {
        "id": "jQHLtSyd09_D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# week 2 slice and list comprehension"
      ],
      "metadata": {
        "id": "D3GQKsK96T7K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "zap = \"hello there bob\"\n",
        "print(zap[4])"
      ],
      "metadata": {
        "id": "lwN0-BWAwOL-",
        "outputId": "c4ec95af-c0ed-48b5-aa4d-09c55169b0b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "o\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "fh= open(\"regex_sum_1904346.txt\")\n",
        "lis=list()\n",
        "for line in fh:\n",
        "    line=line.rstrip()\n",
        "    x=re.findall('[0-9]+',line)\n",
        "    for i in x:\n",
        "      # print(int(i))\n",
        "      lis.append(int(i))\n",
        "\n",
        "print(sum(lis))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0w5vE1-6YDj",
        "outputId": "68cf3442-f1ff-4452-abf2-d9dcf5768c4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "455758\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "print( sum( [ int(x) for x in re.findall('[0-9]+',open(\"regex_sum_1904346.txt\").read()) ] ) )\n",
        "# k=re.findall('[0-9]+',open(\"regex_sum_1904346.txt\").read())\n",
        "# new_list=([int(i) for i in k ])\n",
        "# print(sum(new_list))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yyhm1zJxBY1S",
        "outputId": "5ff50090-af82-433a-f2fb-82065b084eab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "455758\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vF3cdAMjDJPz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "WEEK 3"
      ],
      "metadata": {
        "id": "ytP4hgpWRerl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title An HTTP request\n",
        "import socket\n",
        "my_soc=socket.socket(socket.AF_INET,socket.SOCK_STREAM)\n",
        "my_soc.connect((\"data.pr4e.org\",80))\n",
        "my_soc.close\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xg4y_tNhRhs-",
        "outputId": "54d03a0b-34a6-4145-e32d-ae5bb26a6e3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method socket.close of <socket.socket fd=41, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('172.28.0.12', 39952), raddr=('192.241.136.170', 80)>>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title An HTTP request\n",
        "import socket\n",
        "my_soc=socket.socket(socket.AF_INET,socket.SOCK_STREAM)\n",
        "my_soc.connect((\"data.pr4e.org\",80))\n",
        "cmd='GET http://data.pr4e.org/romeo.txt HTTP/1.0\\r\\n\\r\\n'.encode() #head or body\n",
        "my_soc.send(cmd)\n",
        "while True:\n",
        "  data=my_soc.recv(512)\n",
        "  if(len(data)<1):\n",
        "    break\n",
        "  print(data.decode())\n",
        "my_soc.close\n"
      ],
      "metadata": {
        "id": "_7TdjwmvSiiM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import socket\n",
        "\n",
        "mysock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "mysock.connect(('data.pr4e.org', 80))\n",
        "cmd = 'GET http://data.pr4e.org/intro-short.txt HTTP/1.0\\r\\n\\r\\n'.encode()\n",
        "mysock.send(cmd)\n",
        "\n",
        "while True:\n",
        "    data = mysock.recv(512)\n",
        "    if len(data) < 1:\n",
        "        break\n",
        "    print(data.decode(),end='')\n",
        "\n",
        "mysock.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R1an6f50akM6",
        "outputId": "12f07923-5f9f-49ce-a683-16700479e6a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HTTP/1.1 200 OK\r\n",
            "Date: Mon, 13 Nov 2023 20:41:33 GMT\r\n",
            "Server: Apache/2.4.18 (Ubuntu)\r\n",
            "Last-Modified: Sat, 13 May 2017 11:22:22 GMT\r\n",
            "ETag: \"1d3-54f6609240717\"\r\n",
            "Accept-Ranges: bytes\r\n",
            "Content-Length: 467\r\n",
            "Cache-Control: max-age=0, no-cache, no-store, must-revalidate\r\n",
            "Pragma: no-cache\r\n",
            "Expires: Wed, 11 Jan 1984 05:00:00 GMT\r\n",
            "Connection: close\r\n",
            "Content-Type: text/plain\r\n",
            "\r\n",
            "Why should you learn to write programs?\n",
            "\n",
            "Writing programs (or programming) is a very creative \n",
            "and rewarding activity.  You can write programs for \n",
            "many reasons, ranging from making your living to solving\n",
            "a difficult data analysis problem to having fun to helping\n",
            "someone else solve a problem.  This book assumes that \n",
            "everyone needs to know how to program, and that once \n",
            "you know how to program you will figure out what you want \n",
            "to do with your newfound skills.  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "WEEK 4\n"
      ],
      "metadata": {
        "id": "fu4l-Bq4b3R1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Sum of number in html\n",
        "\n",
        "# To run this, download the BeautifulSoup zip file\n",
        "# http://www.py4e.com/code3/bs4.zip\n",
        "\n",
        "\n",
        "from urllib.request import urlopen\n",
        "from bs4 import BeautifulSoup\n",
        "import ssl\n",
        "\n",
        "# Ignore SSL certificate errors\n",
        "ctx = ssl.create_default_context()\n",
        "ctx.check_hostname = False\n",
        "ctx.verify_mode = ssl.CERT_NONE\n",
        "\n",
        "url = input('Enter - ')\n",
        "html = urlopen(url, context=ctx).read()\n",
        "soup = BeautifulSoup(html, \"html.parser\")\n",
        "count=0\n",
        "sum=0\n",
        "# Retrieve all of the anchor tags\n",
        "tags = soup('span')\n",
        "for tag in tags:\n",
        "    # Look at the parts of a tag\n",
        "    # print('TAG:', tag)\n",
        "   # print('URL:', tag.get('href', None))\n",
        "    # print('Contents:', tag.contents[0])\n",
        "    count=count+1\n",
        "    sum=sum+int(tag.contents[0])\n",
        "    print('Attrs:', tag.attrs)\n",
        "print(\"Count\",count)\n",
        "print(\"Sum\",sum)"
      ],
      "metadata": {
        "id": "dLedLJmYFp1k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title follow nested href count time\n",
        "## tags return fromsoup is resultset not array\n",
        "\n",
        "from urllib.request import urlopen\n",
        "from bs4 import BeautifulSoup\n",
        "import ssl\n",
        "\n",
        "def here(url):\n",
        "  html = ur.urlopen(url).read()\n",
        "  soup = BeautifulSoup(html, 'html.parser')\n",
        "  tags = soup('a')\n",
        "  return tags\n",
        "\n",
        "url=input(\"Enter URL: \")\n",
        "count= int (input(\"Enter count: \"))\n",
        "pos=int (input(\"Enter position: \"))\n",
        "print('Retrieving: ', url)\n",
        "for co in range (count):\n",
        "  # ctx=ssl.create_default_context()\n",
        "  # ctx.check_hostname=False\n",
        "  # ctx.verify_mode=ssl.CERT_NONE\n",
        "  # html=urlopen(url).read()\n",
        "  tags=here(url)\n",
        "  for index, item in enumerate(tags):\n",
        "        if index == pos - 1:\n",
        "            url = item.get('href', None)\n",
        "            name = item.contents[0]\n",
        "            break\n",
        "        else:\n",
        "            continue\n",
        "  print('Retrieving: ', url)\n",
        "  # soup=BeautifulSoup(html,\"html.parser\")\n",
        "  # tags=soup('a')\n"
      ],
      "metadata": {
        "id": "qURhi-QiP8pj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from urllib.request import urlopen\n",
        "from bs4 import BeautifulSoup\n",
        "import ssl\n",
        "\n",
        "\n",
        "url=input(\"Enter URL: \")\n",
        "count= int (input(\"Enter count: \"))\n",
        "position=int (input(\"Enter position: \"))\n",
        "print('Retrieving: ', url)\n",
        "\n",
        "for co in range (count):\n",
        "  ctx=ssl.create_default_context()\n",
        "  ctx.check_hostname=False\n",
        "  ctx.verify_mode=ssl.CERT_NONE\n",
        "\n",
        "  html = urlopen(url,context=ctx).read()\n",
        "  soup = BeautifulSoup(html, 'html.parser')\n",
        "  tags = soup('a')\n",
        "\n",
        "  for index, item in enumerate(tags):\n",
        "        if index == position - 1:\n",
        "            url = item.get('href', None)\n",
        "            name = item.contents[0]\n",
        "            print(item)\n",
        "            break\n",
        "        else:\n",
        "            continue\n",
        "  # print('Retrieving: ', url)\n",
        "\n",
        "\n",
        "# import urllib.request as ur\n",
        "# from bs4 import *\n",
        "\n",
        "# current_repeat_count = 0\n",
        "# url = input('Enter URL: ')\n",
        "# repeat_count = int(input('Enter count: '))\n",
        "# position = int(input('Enter position: '))\n",
        "\n",
        "\n",
        "# def parse_html(url):\n",
        "#     html = ur.urlopen(url).read()\n",
        "#     soup = BeautifulSoup(html, 'html.parser')\n",
        "#     tags = soup('a')\n",
        "#     return tags\n",
        "\n",
        "# while current_repeat_count < repeat_count:\n",
        "#     print('Retrieving: ', url)\n",
        "#     tags = parse_html(url)\n",
        "#     for index, item in enumerate(tags):\n",
        "#         if index == position - 1:\n",
        "#             url = item.get('href', None)\n",
        "#             name = item.contents[0]\n",
        "#             break\n",
        "#         else:\n",
        "#             continue\n",
        "#     current_repeat_count += 1\n",
        "# print('Retrieving: ', url)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPQ-qMFzYG9z",
        "outputId": "ff50d2e7-d61d-42b1-8c1d-0b8bd7a2f4c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter URL: https://py4e-data.dr-chuck.net/known_by_Fikret.html\n",
            "Enter count: 3\n",
            "Enter position: 2\n",
            "Retrieving:  https://py4e-data.dr-chuck.net/known_by_Fikret.html\n",
            "<a href=\"http://py4e-data.dr-chuck.net/known_by_Ogheneruno.html\">Ogheneruno</a>\n",
            "<a href=\"http://py4e-data.dr-chuck.net/known_by_Romi.html\">Romi</a>\n",
            "<a href=\"http://py4e-data.dr-chuck.net/known_by_Sohera.html\">Sohera</a>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(tags\n",
        "           ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52Mnru1aWJHa",
        "outputId": "bde0336c-4f0d-4370-c6b2-b9bc609fc977"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'bs4.element.ResultSet'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title my shortcut without nested loop for resultset\n",
        "\n",
        "import urllib.request as ur\n",
        "from bs4 import *\n",
        "\n",
        "current_repeat_count = 0\n",
        "url = input('Enter URL: ')\n",
        "count = int(input('Enter count: '))\n",
        "pos = int(input('Enter position: '))\n",
        "\n",
        "def parse_html(url,pos):\n",
        "    html = ur.urlopen(url).read()\n",
        "    soup = BeautifulSoup(html, 'html.parser')\n",
        "    tags = soup('a')\n",
        "    return tags[pos-1]\n",
        "for c in range (count):\n",
        "  print('Retrieving: ', url)\n",
        "  item = parse_html(url,pos)\n",
        "  url=item.get('href', None)\n",
        "  name=item.contents[0]\n",
        "print('Last Url: ', url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZaR8uFOZVM1f",
        "outputId": "664bf782-911e-4388-eb4a-0b6ff58be376"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter URL: https://py4e-data.dr-chuck.net/known_by_Fikret.html\n",
            "Enter count: 4\n",
            "Enter position: 3\n",
            "Retrieving:  https://py4e-data.dr-chuck.net/known_by_Fikret.html\n",
            "Retrieving:  http://py4e-data.dr-chuck.net/known_by_Montgomery.html\n",
            "Retrieving:  http://py4e-data.dr-chuck.net/known_by_Mhairade.html\n",
            "Retrieving:  http://py4e-data.dr-chuck.net/known_by_Butchi.html\n",
            "Last Url:  http://py4e-data.dr-chuck.net/known_by_Anayah.html\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title sum from contents\n",
        "\n",
        "from urllib.request import urlopen\n",
        "from bs4 import BeautifulSoup\n",
        "import ssl\n",
        "ctx=ssl.create_default_context()\n",
        "ctx.check_hostname=False\n",
        "ctx.verify_mode=ssl.CERT_NONE\n",
        "\n",
        "url=input('Enter - ')\n",
        "html=urlopen(url,context=ctx).read()\n",
        "soup= BeautifulSoup(html,\"html.parser\")\n",
        "count=0\n",
        "sum=0\n",
        "\n",
        "tags=soup('span')\n",
        "for tag in tags:\n",
        "  count=count+1\n",
        "  sum=sum+int(tag.contents[0])\n",
        "\n",
        "print(\"Count\",count,\"\\nSum\",sum)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1kU8MmALtsj",
        "outputId": "dacb26b5-6137-4db9-ea9b-319193db1845"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter - http://py4e-data.dr-chuck.net/comments_1904348.html\n",
            "Count 50 \n",
            "Sum 2872\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "week 5"
      ],
      "metadata": {
        "id": "uFpAOfxJB-Eh"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h6L9BteCd0YX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request as ur\n",
        "import xml.etree.ElementTree as et\n",
        "\n",
        "url = input('Enter location: ')\n",
        "\n",
        "count = 0\n",
        "sum = 0\n",
        "\n",
        "print('Retrieving', url)\n",
        "xml = urlopen(url).read()\n",
        "print('Retrieved', len(xml), 'characters')\n",
        "\n",
        "tree = et.fromstring(xml)\n",
        "counts = tree.findall('.//count')\n",
        "for count in counts:\n",
        "    sum += int(count.text)\n",
        "    count += 1\n",
        "\n",
        "\n",
        "print('Count:', count)\n",
        "print('Sum:', sum)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "oPgfCHFBd0Zl",
        "outputId": "37ce2e39-1e9f-4da9-8c04-22d17a8b2077"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter location:  http://py4e-data.dr-chuck.net/comments_1904350.xml\n",
            "Retrieving  http://py4e-data.dr-chuck.net/comments_1904350.xml\n",
            "Retrieved 4213 characters\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-56-edecb5391a42>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcounts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0msum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +=: 'xml.etree.ElementTree.Element' and 'int'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request as ur\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "url = input('Enter location: ')\n",
        "total = 0\n",
        "sum = 0\n",
        "\n",
        "\n",
        "print('Retrieving', url)\n",
        "xml = ur.urlopen(url).read()\n",
        "print('Retrieved', len(xml), 'characters')\n",
        "\n",
        "tree = ET.fromstring(xml)\n",
        "counts = tree.findall('.//count')\n",
        "for count in counts:\n",
        "    sum =sum + int(count.text)\n",
        "    total =total+ 1\n",
        "\n",
        "print('Count:', total)\n",
        "print('Sum:', sum)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xBl0x58tZx3o",
        "outputId": "234b7eaf-04b7-46ec-db1f-4906718ee73e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter location: http://py4e-data.dr-chuck.net/comments_1904350.xml\n",
            "Retrieving http://py4e-data.dr-chuck.net/comments_1904350.xml\n",
            "Retrieved 4213 characters\n",
            "Count: 50\n",
            "Sum: 2216\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "week 6\n"
      ],
      "metadata": {
        "id": "M_xzWItteeKF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request as ur\n",
        "import json\n",
        "sum = 0\n",
        "number = 0\n",
        "\n",
        "url = input(\"Enter location: \")\n",
        "print(\"Retrieving \", url)\n",
        "data = ur.urlopen(url).read().decode('utf-8')\n",
        "print('Retrieved', len(data), 'characters')\n",
        "json_obj = json.loads(data)\n",
        "\n",
        "\n",
        "\n",
        "for comment in json_obj[\"comments\"]:\n",
        "    sum =sum + int(comment[\"count\"])\n",
        "    number =number + 1\n",
        "\n",
        "print('Count:', number)\n",
        "print('Sum:', sum)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uxrng9Zjedrr",
        "outputId": "78756438-d6df-4aab-9ac5-c5a4a2ed3d48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter location:  http://py4e-data.dr-chuck.net/comments_1904351.json\n",
            "Retrieving   http://py4e-data.dr-chuck.net/comments_1904351.json\n",
            "Retrieved 2719 characters\n",
            "Count: 50\n",
            "Sum: 2049\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request as ur\n",
        "import urllib.parse as up\n",
        "import json\n",
        "\n",
        "s_url = \"http://python-data.dr-chuck.net/geojson?\"\n",
        "\n",
        "address = input(\"Enter location: \")\n",
        "print(\"Retrieving http://...\")\n",
        "params = {\"sensor\": \"false\", \"address\": address}\n",
        "url = s_url + up.urlencode(params)\n",
        "print(\"Retrieving \", url)\n",
        "\n",
        "data = ur.urlopen(url).read().decode('utf-8')\n",
        "print('Retrieved', len(data), 'characters')\n",
        "json_obj = json.loads(data)\n",
        "\n",
        "place_id = json_obj[\"results\"][0][\"place_id\"]\n",
        "print(\"Place id\", place_id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLPEAyGjf1xd",
        "outputId": "810a4b45-45dc-4c51-df81-a1ffbb880a84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter location: SASTRA University\n",
            "Retrieving  http://python-data.dr-chuck.net/geojson?sensor=false&address=SASTRA+University\n",
            "Retrieved 2156 characters\n",
            "Place id ChIJqSVKHii-qjsRgXSwdYcZJdY\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request, urllib.parse, urllib.error\n",
        "import json\n",
        "import ssl\n",
        "\n",
        "api_key = False\n",
        "\n",
        "if api_key is False:\n",
        "    api_key = 42\n",
        "    serviceurl = 'http://py4e-data.dr-chuck.net/json?'\n",
        "else :\n",
        "    serviceurl = 'https://maps.googleapis.com/maps/api/geocode/json?'\n",
        "\n",
        "\n",
        "address = input('Enter location: ')\n",
        "print(\"Retrieving http://...\")\n",
        "parms = dict()\n",
        "parms['address'] = address\n",
        "if api_key is not False: parms['key'] = api_key\n",
        "url = serviceurl + urllib.parse.urlencode(parms)\n",
        "\n",
        "uhl = urllib.request.urlopen(url, context=ctx)\n",
        "data = uhl.read().decode()\n",
        "print('Retrieved', len(data), 'characters')\n",
        "js = json.loads(data)\n",
        "\n",
        "for place in js['results']:\n",
        "    print(\"Place id\", place['place_id'])\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QF3Q5vbxiFsj",
        "outputId": "2ed87d87-dc7b-4e76-d871-4d2463c47cc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter location: SASTRA University\n",
            "Retrieving http://...\n",
            "Retrieved 2358 characters\n",
            "Place id ChIJlxUhAyi-qjsRHDMCwpYeNwY\n"
          ]
        }
      ]
    }
  ]
}